# -*- coding: utf-8 -*-
"""Копия блокнота "2023 стрелец + проба2024"

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11B_gyw-kz_iB1Dq_OkBZvnJwFP53JK37
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import IsolationForest

# 1. Получение данных и загрузка их в рабочую среду
data = pd.read_csv("/content/drive/MyDrive/База данных/train.csv") # Путь к вашему файлу glass.csv
print(data.head())

# 2. Первичный анализ
print(data['Id'].value_counts())
print(f"Всего записей: {len(data)}")
# Вывод: Классы несбалансированы, что может повлиять на качество модели.

# 3. Разделение выборки и обучение модели
X = data.drop('Id', axis=1)
y = data['Id']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# 4. Предсказание и оценка точности
y_pred = model.predict(X_test)
accuracy_initial = accuracy_score(y_test, y_pred)
print(f"Точность исходной модели: {accuracy_initial}")

# 5. Обработка выбросов
# a) Визуализация распределения значений
plt.figure(figsize=(15, 10))
for i, column in enumerate(X.columns):
    plt.subplot(3, 4, i + 1)
    sns.boxplot(y=X[column])
    plt.title(column)
plt.tight_layout()
plt.show()

plt.figure(figsize=(15, 10))
for i, column in enumerate(X.columns):
    plt.subplot(3, 4, i + 1)
    sns.histplot(X[column], kde=True)  # Используем histplot вместо distplot
    plt.title(column)
plt.tight_layout()
plt.show()

# Вывод: Признаки с нормальным распределением (приблизительно): RI, Na
# b) Исследование признаков на выбросы (метод IQR)
def detect_outliers_iqr(data):
    outlier_indices = []
    for col in data.columns:
        Q1 = data[col].quantile(0.25)
        Q3 = data[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        outliers = data[(data[col] < lower_bound) | (data[col] > upper_bound)].index
        outlier_indices.extend(outliers)
    return outlier_indices

outliers_iqr = detect_outliers_iqr(X)
print(f"Количество выбросов (IQR): {len(set(outliers_iqr))}")

# с) Удаление выбросов
X_no_outliers = X.drop(set(outliers_iqr))
y_no_outliers = y.drop(set(outliers_iqr))

# Calculate percentage of removed records for each class
removed_records_by_class = {}
for class_type in data['Type'].unique():
    initial_count = len(data[data['Type'] == class_type])
    remaining_count = len(y_no_outliers[data['Type'][y_no_outliers.index] == class_type]) # Use y_no_outliers index

    removed_count = initial_count - remaining_count
    percentage_removed = (removed_count / initial_count) * 100 if initial_count > 0 else 0
    removed_records_by_class[class_type] = percentage_removed

print("Процент удаленных записей от общего числа записей для каждого класса:")
print(removed_records_by_class)

print(f"Размер X до удаления выбросов: {X.shape}")
print(f"Размер X после удаления выбросов: {X_no_outliers.shape}")

# 6. Повторение шагов 3 и 4 с данными без выбросов
X_train_no_outliers, X_test_no_outliers, y_train_no_outliers, y_test_no_outliers = train_test_split(
    X_no_outliers, y_no_outliers, test_size=0.2, random_state=42
)

model_no_outliers = RandomForestClassifier(random_state=42)
model_no_outliers.fit(X_train_no_outliers, y_train_no_outliers)

y_pred_no_outliers = model_no_outliers.predict(X_test_no_outliers)
accuracy_no_outliers = accuracy_score(y_test_no_outliers, y_pred_no_outliers)
print(f"Точность модели после обработки выбросов: {accuracy_no_outliers}")

# 7. Выводы
# a) Описание преобразований:
print("\nВыводы:")
print("a) С данными были произведены следующие преобразования:")
print("- Исследованы на наличие выбросов с использованием boxplot и IQR.")
print("- Выбросы были удалены из датасета.")
print("- Процент удаленных записей для каждого класса был рассчитан.")

# b) Сравнение точности моделей:
print(f"b) Сравнение точности моделей:")
print(f"- Точность исходной модели: {accuracy_initial}")
print(f"- Точность модели после обработки выбросов: {accuracy_no_outliers}")

# c) Мнение о необходимости исследования данных на выбросы:
print("c) Нужно ли исследовать данные на выбросы, для чего это делается, плюсы и минусы подхода:")
print("Исследование данных на выбросы важно, так как выбросы могут искажать результаты обучения модели и приводить к ухудшению ее обобщающей способности.")
print("Плюсы подхода:")
print("- Улучшение качества данных и, как следствие, повышение точности модели.")
print("- Более надежные и интерпретируемые результаты.")
print("Минусы подхода:")
print("- Удаление выбросов может привести к потере ценной информации, особенно если выбросы являются результатом редких, но важных событий.")
print("- Выбор метода обработки выбросов и параметров (например, коэффициента IQR) может быть субъективным и влиять на результаты.")

"""Задание 1: Прогнозирование остаточного ресурса железобетонных конструкций

Описание: Надежность и долговечность железобетонных конструкций критически важны для безопасности зданий и сооружений. Коррозия арматуры является одной из основных причин их разрушения. В этом задании вам предстоит разработать модель машинного обучения, предсказывающую остаточный ресурс железобетонной конструкции на основе данных о ее состоянии и условиях эксплуатации.

Данные: Предоставляется датасет, содержащий информацию о железобетонных конструкциях:

Age (лет) - возраст конструкции
ConcreteStrength (МПа) - прочность бетона
ReinforcementRatio (%) - процент армирования
ChlorideContent (%) - содержание хлоридов в бетоне
ExposureType (категориальный) - тип воздействия окружающей среды (например, морской климат, промышленная зона)
CorrosionRate (мкм/год) - скорость коррозии арматуры (измерено)
RemainingLife (лет) - остаточный срок службы (целевая переменная)
Задачи:

Первичный анализ: Загрузите данные, изучите их структуру и основные статистики. Визуализируйте распределение целевой переменной и основных признаков. Оцените наличие пропущенных значений и выбросов.
Подготовка данных: Обработайте категориальные признаки (например, с помощью one-hot encoding). Разделите данные на обучающую и тестовую выборки (80/20).
Разработка модели: Попробуйте различные алгоритмы машинного обучения для регрессии (например, линейная регрессия, случайный лес, градиентный бустинг, нейронные сети). Подберите оптимальные гиперпараметры для выбранной модели.
Оценка производительности: Оцените качество модели на тестовой выборке с использованием метрик RMSE, MAE, R2.
Интерпретация результатов: Объясните, какие факторы оказывают наибольшее влияние на остаточный ресурс железобетонной конструкции.
Оценка:

Полнота и корректность выполнения задач.
Качество модели прогнозирования (точность, интерпретируемость).
Обоснованность выбора алгоритмов и гиперпараметров.
Четкость и логичность выводов.
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import OneHotEncoder

# Создаем данные
data = {
    'Age': [5, 12, 25, 18, 3, 30, 10, 22, 7, 15, 4, 28, 9, 19, 6, 23, 11, 17, 2, 29, 8, 21],
    'ConcreteStrength': [38.5, 42.1, 35.2, 40.7, 46.8, 32.5, 39.9, 36.1, 44.3, 37.8, 47.5, 33.2, 41.6, 34.9, 45.1, 35.8, 40.3, 37.5, 48.2, 32.9, 42.4, 36.5],
    'ReinforcementRatio': [1.3, 1.6, 1.1, 1.4, 1.7, 0.9, 1.5, 1.2, 1.8, 1.3, 1.9, 1.0, 1.6, 1.1, 1.7, 1.2, 1.5, 1.3, 2.0, 0.95, 1.65, 1.15],
    'ChlorideContent': [0.01, 0.03, 0.08, 0.05, 0.005, 0.12, 0.02, 0.09, 0.008, 0.06, 0.003, 0.11, 0.015, 0.07, 0.007, 0.085, 0.025, 0.055, 0.002, 0.115, 0.012, 0.075],
    'ExposureType': ['Rural', 'Urban', 'Marine', 'Industrial', 'Rural', 'Marine', 'Urban', 'Industrial', 'Rural', 'Marine', 'Rural', 'Industrial', 'Urban', 'Marine', 'Rural', 'Industrial', 'Urban', 'Marine', 'Rural', 'Industrial', 'Urban', 'Marine'],
    'CorrosionRate': [5.2, 8.7, 15.1, 12.3, 3.9, 18.9, 7.5, 14.6, 4.7, 11.8, 3.2, 17.2, 6.4, 13.5, 4.3, 14.9, 7.1, 12.1, 2.9, 17.5, 5.9, 13.8],
    'RemainingLife': [85, 68, 42, 55, 92, 30, 75, 45, 88, 58, 95, 35, 72, 48, 90, 43, 70, 56, 97, 33, 69, 46]
}

df = pd.DataFrame(data)
df.to_csv('concrete_data_realistic.csv', index=False)

print("Файл concrete_data_realistic.csv успешно создан.")


# Далее можно добавить код для обработки, обучения и оценки, как в предыдущем примере

# Обработка категориальных переменных
encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)
encoder.fit(df[['ExposureType']])
encoded_cols = encoder.transform(df[['ExposureType']])
encoded_df = pd.DataFrame(encoded_cols, columns=encoder.get_feature_names_out(['ExposureType']))
df = pd.concat([df, encoded_df], axis=1)
df = df.drop('ExposureType', axis=1)

# Подготовка данных для модели
X = df.drop('RemainingLife', axis=1)
y = df['RemainingLife']

# Разделение на обучающую и тестовую выборки
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Обучение модели (RandomForestRegressor)
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Предсказание на тестовой выборке
y_pred = model.predict(X_test)

# Оценка качества модели
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print(f'RMSE: {rmse:.2f}')
print(f'R2: {r2:.2f}')

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Создаем данные (пример)
data = {
    'Age': [5, 12, 25, 18, 3, 30, 10, 22, 7, 15, 4, 28, 9, 19, 6, 23, 11, 17, 2, 29],
    'ConcreteStrength': [38.5, 42.1, 35.2, 40.7, 46.8, 32.5, 39.9, 36.1, 44.3, 37.8, 47.5, 33.2, 41.6, 34.9, 45.1, 35.8, 40.3, 37.5, 48.2, 32.9],
    'ReinforcementRatio': [1.3, 1.6, 1.1, 1.4, 1.7, 0.9, 1.5, 1.2, 1.8, 1.3, 1.9, 1.0, 1.6, 1.1, 1.7, 1.2, 1.5, 1.3, 2.0, 0.95],
    'ChlorideContent': [0.01, 0.03, 0.08, 0.05, 0.005, 0.12, 0.02, 0.09, 0.008, 0.06, 0.003, 0.11, 0.015, 0.07, 0.007, 0.085, 0.025, 0.055, 0.002, 0.115],
    'ExposureType': ['Rural', 'Urban', 'Marine', 'Industrial', 'Rural', 'Marine', 'Urban', 'Industrial', 'Rural', 'Marine', 'Rural', 'Industrial', 'Urban', 'Marine', 'Rural', 'Industrial', 'Urban', 'Marine', 'Rural', 'Industrial'],
    'CorrosionRate': [5.2, 8.7, 15.1, 12.3, 3.9, 18.9, 7.5, 14.6, 4.7, 11.8, 3.2, 17.2, 6.4, 13.5, 4.3, 14.9, 7.1, 12.1, 2.9, 17.5],
    'RemainingLife': [85, 68, 42, 55, 92, 30, 75, 45, 88, 58, 95, 35, 72, 48, 90, 43, 70, 56, 97, 33]
}

df = pd.DataFrame(data)

# 1. Первичный анализ и визуализация

# Общая информация о данных
print("Общая информация о данных:")
print(df.info())

# Основные статистики
print("\nОсновные статистики:")
print(df.describe())

# Распределение целевой переменной (RemainingLife)
plt.figure(figsize=(8, 6))
sns.histplot(df['RemainingLife'], kde=True)
plt.title('Распределение остаточного срока службы')
plt.xlabel('Остаточный срок службы (лет)')
plt.ylabel('Частота')
plt.show()

# Графики рассеяния для численных признаков по отношению к целевой переменной
numerical_features = ['Age', 'ConcreteStrength', 'ReinforcementRatio', 'ChlorideContent', 'CorrosionRate']
for feature in numerical_features:
    plt.figure(figsize=(8, 6))
    sns.scatterplot(x=feature, y='RemainingLife', data=df)
    plt.title(f'Зависимость остаточного срока службы от {feature}')
    plt.xlabel(feature)
    plt.ylabel('Остаточный срок службы (лет)')
    plt.show()

# Boxplot для категориального признака (ExposureType) по отношению к целевой переменной
plt.figure(figsize=(8, 6))
sns.boxplot(x='ExposureType', y='RemainingLife', data=df)
plt.title('Остаточный срок службы по типам воздействия окружающей среды')
plt.xlabel('Тип воздействия окружающей среды')
plt.ylabel('Остаточный срок службы (лет)')
plt.show()

# Матрица корреляции для численных признаков
numeric_df = df.select_dtypes(include=np.number) # выбираем только числовые столбцы
correlation_matrix = numeric_df.corr()
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Матрица корреляции')
plt.show()

# Выявление выбросов (пример с использованием boxplot)
plt.figure(figsize=(12, 8))
sns.boxplot(data=df[numerical_features])
plt.title('Ящики с усами для выявления выбросов')
plt.ylabel('Значение')
plt.xticks(rotation=45)
plt.show()

# Дополнительные графики (по желанию):
# - Pairplot для анализа попарных зависимостей
# - Violin plot для анализа распределения данных

print("Закончили отрисовку графиков")

"""Задание 2: Классификация типов повреждений зданий на основе анализа изображений

Описание: Автоматическое выявление повреждений зданий по изображениям может значительно ускорить процесс инспекции и оценки состояния. В этом задании вам предстоит разработать систему классификации типов повреждений зданий с использованием сверточных нейронных сетей (CNN).

Данные: Предоставляется набор изображений с различными типами повреждений зданий:

Crack - трещины Spalling - отслоение бетона Corrosion - коррозия арматуры WaterDamage - повреждения от воды Intact - нет повреждений Задачи:

Подготовка данных: Загрузите изображения, приведите их к единому размеру и формату. Разделите данные на обучающую и валидационную выборки (80/20). Разработка модели CNN: Создайте архитектуру сверточной нейронной сети для классификации изображений. Можете использовать готовые архитектуры (например, VGG16, ResNet50) с применением Transfer Learning. Обучение модели: Обучите CNN на обучающей выборке, используя аугментацию данных для улучшения обобщающей способности. Оценка производительности: Оцените качество классификации на валидационной выборке с использованием метрик accuracy, precision, recall, F1-score. Визуализация результатов: Визуализируйте результаты классификации (например, confusion matrix, примеры правильных и неправильных предсказаний). Оценка:

Качество классификации повреждений. Обоснованность выбора архитектуры CNN и параметров обучения. Эффективность использования аугментации данных. Интерпретируемость результатов и предложенные способы улучшения модели.
"""

import tensorflow as tf
from tensorflow.keras.preprocessing import image_dataset_from_directory
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
import matplotlib.pyplot as plt

# Каталог с изображениями
data_dir = "damage_images"
# Размеры изображений
image_size = (224, 224)
batch_size = 32

# Создание обучающего и валидационного наборов данных
train_ds = image_dataset_from_directory(
    data_dir,
    validation_split=0.2,
    subset="training",
    seed=42,
    image_size=image_size,
    batch_size=batch_size
)

val_ds = image_dataset_from_directory(
    data_dir,
    validation_split=0.2,
    subset="validation",
    seed=42,
    image_size=image_size,
    batch_size=batch_size
)

model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(len(train_ds.class_names), activation='softmax') # Кол-во классов
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(train_ds,
                    validation_data=val_ds,
                    epochs=10)

# Вывод графиков обучения
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

loss, accuracy = model.evaluate(val_ds)
print(f"Accuracy on validation set: {accuracy}")

import os
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
from sklearn.model_selection import train_test_split
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report

# Задайте путь к директории с изображениями
data_dir = 'damage_images'  # Замените на свой путь

# Определение классов
classes = ['Crack', 'Spalling', 'Corrosion', 'WaterDamage', 'Intact']

# Функция для загрузки изображений и меток
def load_data(data_dir, classes, img_size=(224, 224)):
    images = []
    labels = []
    for class_name in classes:
        class_dir = os.path.join(data_dir, class_name)
        for img_name in os.listdir(class_dir):
            img_path = os.path.join(class_dir, img_name)
            try:
                img = Image.open(img_path).resize(img_size)
                img = np.array(img) / 255.0  # Нормализация
                images.append(img)
                labels.append(class_name)
            except Exception as e:
                print(f"Ошибка при загрузке изображения {img_path}: {e}")
    return np.array(images), np.array(labels)

# Загрузка данных
images, labels = load_data(data_dir, classes)

# Разделение данных на обучающую и тестовую выборки
X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42, stratify=labels)

# 1. Визуализация распределения классов
plt.figure(figsize=(8, 6))
sns.countplot(x=y_train)
plt.title('Распределение классов в обучающей выборке')
plt.xlabel('Тип повреждения')
plt.ylabel('Количество изображений')
plt.show()

# 2. Отображение нескольких примеров изображений из каждого класса
num_samples = 3
fig, axes = plt.subplots(len(classes), num_samples, figsize=(12, 8))
fig.suptitle('Примеры изображений из каждого класса', fontsize=16)

for i, class_name in enumerate(classes):
    class_indices = np.where(y_train == class_name)[0]
    random_indices = np.random.choice(class_indices, num_samples, replace=False)
    for j, idx in enumerate(random_indices):
        ax = axes[i, j]
        ax.imshow(X_train[idx])
        ax.set_title(class_name)
        ax.axis('off')

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

# 3. После обучения модели CNN:

# Предположим, у вас есть обученная модель и вы получили предсказания
# y_pred = model.predict(X_test) # Замените это на ваши фактические предсказания

# Преобразуйте текстовые метки в числовые для confusion matrix и classification report
label_encoder = LabelEncoder()
y_test_encoded = label_encoder.fit_transform(y_test)
# Замените следующую строку на ваши предсказания
y_pred_encoded = label_encoder.transform(np.random.choice(classes, len(y_test)))  # ЗАМЕНИТЕ!
# Сгенерируйте случайные данные для демонстрации, необходимо заменить на реальные предсказания

# Матрица ошибок
cm = confusion_matrix(y_test_encoded, y_pred_encoded)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=classes, yticklabels=classes)
plt.title('Матрица ошибок')
plt.xlabel('Предсказанный класс')
plt.ylabel('Истинный класс')
plt.show()

# Отчет о классификации
print("Отчет о классификации:")
print(classification_report(y_test_encoded, y_pred_encoded, target_names=classes))

# Вывод:
# Вы должны заменить `y_pred = model.predict(X_test)` на ваши фактические предсказания,
# чтобы иметь корректные результаты в матрице ошибок и отчете о классификации.

"""Задание 3: Оптимизация энергопотребления здания с использованием Reinforcement Learning

Описание: Оптимизация энергопотребления зданий является важной задачей для повышения их энергоэффективности и снижения затрат. В этом задании вам предстоит разработать систему управления энергопотреблением здания на основе алгоритмов Reinforcement Learning (RL).

Данные: Предоставляется симулятор здания, генерирующий данные о:

OutsideTemperature (°C) - температура окружающей среды InsideTemperature (°C) - температура внутри здания Occupancy (0/1) - наличие людей в здании TimeOfDay (час) - время суток EnergyConsumption (кВтч) - текущее энергопотребление Действия: HeatingSetpoint (°C) - уставка температуры для отопления CoolingSetpoint (°C) - уставка температуры для охлаждения Задачи:

Разработка среды RL: Создайте среду RL, имитирующую процесс управления энергопотреблением здания. Определите состояние, действия, награду (например, минимизация энергопотребления при поддержании комфортной температуры). Реализация алгоритма RL: Реализуйте алгоритм RL (например, Q-learning, SARSA, Deep Q-Network) для обучения агента управлению энергопотреблением. Обучение агента: Обучите агента RL в симулированной среде. Оценка производительности: Оцените эффективность обученного агента в управлении энергопотреблением по сравнению с базовым сценарием (например, фиксированные уставки температуры). Оценка:

Эффективность снижения энергопотребления. Обоснованность выбора алгоритма RL и параметров обучения. Качество разработки среды RL (реалистичность, масштабируемость). Анализ поведения агента и предложенные способы улучшения системы. Ключевые моменты:

Реальные данные: Подчеркните важность использования реальных данных, собранных с датчиков и строительных площадок. Проблемы и решения: Ориентируйте задания на решение реальных проблем строительной отрасли. Актуальность: Выбирайте темы, которые являются актуальными и перспективными в области машинного обучения и строительства. Критерии оценки: Четко определите критерии оценки, чтобы участники понимали, что ожидается от них. Творчество и инновации: Поощряйте творческий подход и инновационные решения. Эти задания требуют не только знания теории машинного обучения, но и понимания специфики строительных процессов и умения применять эти знания для решения практических задач.
"""

import gym
from gym import spaces
import numpy as np

class BuildingEnv(gym.Env):
    def __init__(self):
        super(BuildingEnv, self).__init__()
        # Определите пространство действий (HeatingSetpoint, CoolingSetpoint)
        self.action_space = spaces.Box(low=15, high=30, shape=(2,), dtype=np.float32)
        # Определите пространство состояний (OutsideTemperature, InsideTemperature, Occupancy, TimeOfDay)
        self.observation_space = spaces.Box(low=0, high=40, shape=(4,), dtype=np.float32)
        self.state = None
        self.time_step = 0

    def reset(self):
        # Начальное состояние
        self.state = np.array([20, 22, 0, 8]) # OutsideTemp, InsideTemp, Occupancy, Time
        self.time_step = 0
        return self.state

    def step(self, action):
        heating_setpoint, cooling_setpoint = action
        outside_temperature, inside_temperature, occupancy, time_of_day = self.state

        # Имитация потребления энергии (упрощенная модель)
        energy_consumption = abs(heating_setpoint - inside_temperature) + abs(cooling_setpoint - inside_temperature) + occupancy * 5

        # Награда (минимизация энергопотребления и поддержание комфорта)
        reward = -energy_consumption - abs(inside_temperature - 22)

        # Обновление состояния (упрощенно)
        self.state = np.array([outside_temperature + np.random.normal(0, 1),
                               inside_temperature + (heating_setpoint - inside_temperature) * 0.1 + (cooling_setpoint - inside_temperature) * 0.1 + np.random.normal(0, 0.5),
                               occupancy,
                               (time_of_day + 1) % 24])
        self.time_step += 1
        done = self.time_step >= 24 * 30 # 30 дней

        return self.state, reward, done, {}

import random

# Q-Learning (пример)
class QLearningAgent:
    def __init__(self, env, learning_rate=0.1, discount_factor=0.9, exploration_rate=0.2):
        self.env = env
        self.q_table = {} # Q-таблица
        self.learning_rate = learning_rate
        self.discount_factor = discount_factor
        self.exploration_rate = exploration_rate

    def choose_action(self, state):
        if random.uniform(0, 1) < self.exploration_rate:
            return self.env.action_space.sample() # Случайное действие
        else:
            if tuple(state) in self.q_table:
                return self.q_table[tuple(state)]
            else:
                return self.env.action_space.sample()

    def learn(self, state, action, reward, next_state):
        if tuple(state) not in self.q_table:
            self.q_table[tuple(state)] = self.env.action_space.sample() # Инициализация случайным действием
        old_value = self.q_table[tuple(state)]
        if tuple(next_state) in self.q_table:
             next_max = np.max(self.q_table[tuple(next_state)]) #нашли макс награду в новой точке
        else:
             next_max = 0
        new_value = (1 - self.learning_rate) * old_value + self.learning_rate * (reward + self.discount_factor * next_max)
        self.q_table[tuple(state)] = new_value


env = BuildingEnv()
agent = QLearningAgent(env)

# Обучение
episodes = 1000
for episode in range(episodes):
    state = env.reset()
    done = False
    while not done:
        action = agent.choose_action(state)
        next_state, reward, done, _ = env.step(action)
        agent.learn(state, action, reward, next_state)
        state = next_state

import gym
from gym import spaces
import numpy as np

class BuildingEnv(gym.Env):
    def __init__(self):
        super(BuildingEnv, self).__init__()
        # Определите пространство действий (HeatingSetpoint, CoolingSetpoint)
        self.action_space = spaces.Box(low=15, high=30, shape=(2,), dtype=np.float32)
        # Определите пространство состояний (OutsideTemperature, InsideTemperature, Occupancy, TimeOfDay)
        self.observation_space = spaces.Box(low=np.array([0, 15, 0, 0]), high=np.array([40, 30, 1, 23]), shape=(4,), dtype=np.float32)
        self.state = None
        self.time_step = 0

    def reset(self, seed=None, options=None):
        super().reset(seed=seed)  # Добавьте seed для детерминированности, если нужно
        # Начальное состояние
        self.state = np.array([20, 22, 0, 8], dtype=np.float32)  # OutsideTemp, InsideTemp, Occupancy, Time
        self.time_step = 0
        return self.state, {} # Gym API требует возврата state и info (словаря)

    def step(self, action):
        heating_setpoint, cooling_setpoint = action

        # Проверка на допустимые значения действия
        heating_setpoint = np.clip(heating_setpoint, self.action_space.low[0], self.action_space.high[0])
        cooling_setpoint = np.clip(cooling_setpoint, self.action_space.low[1], self.action_space.high[1])

        outside_temperature, inside_temperature, occupancy, time_of_day = self.state

        # Имитация потребления энергии (упрощенная модель)
        energy_consumption = abs(heating_setpoint - inside_temperature) + abs(cooling_setpoint - inside_temperature) + occupancy * 5

        # Награда (минимизация энергопотребления и поддержание комфорта)
        reward = -energy_consumption - abs(inside_temperature - 22)

        # Обновление состояния (упрощенно)
        new_outside_temperature = outside_temperature + np.random.normal(0, 1)
        new_inside_temperature = inside_temperature + (heating_setpoint - inside_temperature) * 0.1 + (cooling_setpoint - inside_temperature) * 0.1 + np.random.normal(0, 0.5)
        new_occupancy = occupancy # occupancy остается прежней
        new_time_of_day = (time_of_day + 1) % 24

        # Ограничиваем значения
        new_outside_temperature = np.clip(new_outside_temperature, self.observation_space.low[0], self.observation_space.high[0])
        new_inside_temperature = np.clip(new_inside_temperature, self.observation_space.low[1], self.observation_space.high[1])

        self.state = np.array([new_outside_temperature, new_inside_temperature, occupancy, new_time_of_day], dtype=np.float32)

        self.time_step += 1
        done = self.time_step >= 24 * 30  # 30 дней

        truncated = False # truncated должен быть False, пока не указано обратное
        return self.state, reward, done, truncated, {} # Gym API требует возврата state, reward, done, truncated, info

import random

# Q-Learning (пример)
class QLearningAgent:
    def __init__(self, env, learning_rate=0.1, discount_factor=0.9, exploration_rate=0.2):
        self.env = env
        self.q_table = {} # Q-таблица
        self.learning_rate = learning_rate
        self.discount_factor = discount_factor
        self.exploration_rate = exploration_rate

    def discretize_state(self, state, num_buckets=10):
        """Дискретизация непрерывного состояния для Q-learning."""
        # Размер каждого "ведра" для каждого измерения состояния
        bucket_sizes = (self.env.observation_space.high - self.env.observation_space.low) / num_buckets
        # Вычисляем индекс "ведра" для каждого измерения состояния
        discretized = ((state - self.env.observation_space.low) / bucket_sizes).astype(int)
        # Убедимся, что индексы находятся в пределах допустимых значений
        return tuple(np.clip(discretized, 0, num_buckets - 1))


    def choose_action(self, state):
        discretized_state = self.discretize_state(state)
        if random.uniform(0, 1) < self.exploration_rate:
            return self.env.action_space.sample() # Случайное действие
        else:
            if discretized_state in self.q_table:
                return self.q_table[discretized_state]
            else:
                return self.env.action_space.sample()

    def learn(self, state, action, reward, next_state):
        discretized_state = self.discretize_state(state)
        discretized_next_state = self.discretize_state(next_state)

        if discretized_state not in self.q_table:
            self.q_table[discretized_state] = (self.env.action_space.sample())  # Инициализация случайным действием

        if discretized_next_state not in self.q_table:
             self.q_table[discretized_next_state] = (self.env.action_space.sample())

        old_value = self.q_table[discretized_state]

        next_max = np.max(self.q_table[discretized_next_state])
        new_value = (1 - self.learning_rate) * old_value + self.learning_rate * (reward + self.discount_factor * next_max)

        self.q_table[discretized_state] = new_value


env = BuildingEnv()
agent = QLearningAgent(env)

# Обучение
episodes = 1000

for episode in range(episodes):
    state, _ = env.reset() #reset возвращает кортеж (state, info), поэтому необходимо его распаковать.
    done = False
    truncated = False
    total_reward = 0

    while not done and not truncated:
        action = agent.choose_action(state)
        next_state, reward, done, truncated, _ = env.step(action)
        agent.learn(state, action, reward, next_state)
        state = next_state
        total_reward += reward

    if (episode + 1) % 100 == 0:
        print(f"Episode {episode + 1}, Total Reward: {total_reward}")

"""Задание 4: Классификация типов грунтов по данным геологических изысканий

Описание: Определение типа грунта является важным этапом при проектировании фундаментов зданий и сооружений. Неправильная оценка свойств грунта может привести к серьезным проблемам, таким как просадки, деформации и разрушения. В этом задании вам предстоит разработать модель машинного обучения, классифицирующую типы грунтов на основе данных геологических изысканий.

Данные: Предоставляется датасет с результатами геологических изысканий:

Depth (м) - глубина измерения
SPT_N (уд/м) - количество ударов при стандартном пенетрационном тесте (SPT)
WaterContent (%) - влажность грунта
PlasticityIndex (%) - индекс пластичности
LiquidLimit (%) - предел текучести
ClayContent (%) - содержание глинистых частиц
SiltContent (%) - содержание пылеватых частиц
SandContent (%) - содержание песчаных частиц
GravelContent (%) - содержание гравийных частиц
SoilType (категориальный) - тип грунта (целевая переменная): Sand, Clay, Silt, Gravel, Loam
Этапы работы: (Повторяют структуру исходного задания)

Получите данные и загрузите их в рабочую среду (Jupyter Notebook или другую).
Проведите первичный анализ. Проверьте количество записей для каждого класса (SoilType). Сделайте вывод.
Разделите выборку на обучающее и тестовое подмножество. 80% данных оставить на обучающее множество, 20% на тестовое. Обучите модель дерева решений RandomForestClassifier на обучающем множестве.
Для тестового множества предскажите тип грунта и сравните с истинным значением, посчитав точность предсказания модели (accuracy).
Обработайте выбросы в данных: а) Визуализируйте распределение значений для каждой переменной. Можно использовать функции sns.boxplot, sns.distplot. Есть ли признаки с нормальным распределением? b) Исследуйте признаки на выбросы несколькими способами. c) Удалите выбросы. *Посчитайте процент удаленных записей от общего числа записей для каждого класса.
Повторите п. 4, п. 5.
Сформулируйте выводы по проделанной работе: а) Кратко опишите, какие преобразования были сделаны с данными. b) Сравните точность двух моделей. c) Напишите свое мнение, нужно ли исследовать данные на выбросы, для чего это делается, плюсы и минусы подхода.
Инструменты:

Jupyter Notebook/Google Colab
GitHub
данные для обучения моделей (предоставляются)
модель дерева решений RandomForestClassifier
"""

import gym
from gym import spaces
import numpy as np
import matplotlib.pyplot as plt
import random
import seaborn as sns
import pandas as pd

class BuildingEnv(gym.Env):
    def __init__(self):
        super(BuildingEnv, self).__init__()
        # Определите пространство действий (HeatingSetpoint, CoolingSetpoint)
        self.action_space = spaces.Box(low=15, high=30, shape=(2,), dtype=np.float32)
        # Определите пространство состояний (OutsideTemperature, InsideTemperature, Occupancy, TimeOfDay)
        self.observation_space = spaces.Box(low=np.array([0, 15, 0, 0]), high=np.array([40, 30, 1, 23]), shape=(4,), dtype=np.float32)
        self.state = None
        self.time_step = 0
        self.episode_history = [] # Список для хранения данных об эпизоде

    def reset(self, seed=None, options=None):
        super().reset(seed=seed)  # Добавьте seed для детерминированности, если нужно
        # Начальное состояние
        self.state = np.array([20, 22, 0, 8], dtype=np.float32)  # OutsideTemp, InsideTemp, Occupancy, Time
        self.time_step = 0
        self.episode_history = [] # Сбрасываем историю эпизода
        return self.state, {} # Gym API требует возврата state и info (словаря)

    def step(self, action):
        heating_setpoint, cooling_setpoint = action

        # Проверка на допустимые значения действия
        heating_setpoint = np.clip(heating_setpoint, self.action_space.low[0], self.action_space.high[0])
        cooling_setpoint = np.clip(cooling_setpoint, self.action_space.low[1], self.action_space.high[1])

        outside_temperature, inside_temperature, occupancy, time_of_day = self.state

        # Имитация потребления энергии (упрощенная модель)
        energy_consumption = abs(heating_setpoint - inside_temperature) + abs(cooling_setpoint - inside_temperature) + occupancy * 5

        # Награда (минимизация энергопотребления и поддержание комфорта)
        reward = -energy_consumption - abs(inside_temperature - 22)

        # Обновление состояния (упрощенно)
        new_outside_temperature = outside_temperature + np.random.normal(0, 1)
        new_inside_temperature = inside_temperature + (heating_setpoint - inside_temperature) * 0.1 + (cooling_setpoint - inside_temperature) * 0.1 + np.random.normal(0, 0.5)
        new_occupancy = occupancy # occupancy остается прежней
        new_time_of_day = (time_of_day + 1) % 24

        # Ограничиваем значения
        new_outside_temperature = np.clip(new_outside_temperature, self.observation_space.low[0], self.observation_space.high[0])
        new_inside_temperature = np.clip(new_inside_temperature, self.observation_space.low[1], self.observation_space.high[0])

        self.state = np.array([new_outside_temperature, new_inside_temperature, occupancy, new_time_of_day], dtype=np.float32)

        self.time_step += 1
        done = self.time_step >= 24 * 30  # 30 дней

        truncated = False # truncated должен быть False, пока не указано обратное

        # Сохраняем данные для графиков
        self.episode_history.append({
            'OutsideTemperature': outside_temperature,
            'InsideTemperature': inside_temperature,
            'HeatingSetpoint': heating_setpoint,
            'CoolingSetpoint': cooling_setpoint,
            'EnergyConsumption': energy_consumption,
            'Reward': reward,
            'TimeOfDay': time_of_day
        })

        return self.state, reward, done, truncated, {} # Gym API требует возврата state, reward, done, truncated, info

    def render_episode(self, episode_num):
        """Функция для отрисовки графиков по окончании эпизода"""

        episode_df = pd.DataFrame(self.episode_history)
        time = np.arange(len(episode_df))

        # 1. График температур (внутри, снаружи, уставки)
        plt.figure(figsize=(12, 6))
        plt.plot(time, episode_df['OutsideTemperature'], label='Температура снаружи', alpha=0.7)
        plt.plot(time, episode_df['InsideTemperature'], label='Температура внутри', alpha=0.7)
        plt.plot(time, episode_df['HeatingSetpoint'], label='Уставка отопления', linestyle='--', alpha=0.7)
        plt.plot(time, episode_df['CoolingSetpoint'], label='Уставка охлаждения', linestyle='--', alpha=0.7)
        plt.xlabel('Шаг времени')
        plt.ylabel('Температура (°C)')
        plt.title(f'Температуры в течение эпизода {episode_num}')
        plt.legend()
        plt.grid(True)
        plt.show()

        # 2. График энергопотребления
        plt.figure(figsize=(12, 4))
        plt.plot(time, episode_df['EnergyConsumption'], label='Энергопотребление', color='red')
        plt.xlabel('Шаг времени')
        plt.ylabel('Энергопотребление (кВтч)')
        plt.title(f'Энергопотребление в течение эпизода {episode_num}')
        plt.legend()
        plt.grid(True)
        plt.show()

        # 3. Гистограмма наград
        plt.figure(figsize=(8, 5))
        sns.histplot(episode_df['Reward'], kde=True, color='green')
        plt.xlabel('Награда')
        plt.ylabel('Частота')
        plt.title(f'Распределение наград в течение эпизода {episode_num}')
        plt.show()

        # 4. Зависимость энергопотребления от времени суток
        plt.figure(figsize=(10, 5))
        sns.lineplot(x='TimeOfDay', y='EnergyConsumption', data=episode_df)
        plt.title(f'Энергопотребление в зависимости от времени суток (Эпизод {episode_num})')
        plt.xlabel('Время суток (час)')
        plt.ylabel('Энергопотребление (кВтч)')
        plt.grid(True)
        plt.show()

from collections import defaultdict

class QLearningAgent:
    def __init__(self, env, learning_rate=0.1, discount_factor=0.9, exploration_rate=0.2, num_buckets=10):
        self.env = env
        self.q_table = defaultdict(lambda: np.zeros(env.action_space.shape)) # Q-таблица
        self.learning_rate = learning_rate
        self.discount_factor = discount_factor
        self.exploration_rate = exploration_rate
        self.num_buckets = num_buckets # Количество "корзин" для дискретизации

    def discretize_state(self, state):
        """Дискретизация непрерывного состояния для Q-learning."""
        bucket_sizes = (self.env.observation_space.high - self.env.observation_space.low) / self.num_buckets
        discretized = ((state - self.env.observation_space.low) / bucket_sizes).astype(int)
        return tuple(np.clip(discretized, 0, self.num_buckets - 1))

    def choose_action(self, state):
        """Выбор действия на основе стратегии exploration-exploitation."""
        if random.uniform(0, 1) < self.exploration_rate:
            # Исследование: выбираем случайное действие
            return self.env.action_space.sample()
        else:
            # Эксплуатация: выбираем лучшее известное действие для данного состояния
            discretized_state = self.discretize_state(state)
            return self.choose_best_action(discretized_state)

    def choose_best_action(self, state):
          """Выбор наилучшего действия из Q-таблицы"""
          if state not in self.q_table:
              return self.env.action_space.sample() # Если состояние новое, выбираем случайное действие
          else:
              return self.q_table[state]  # Возвращаем действие, соответствующее максимальному Q-значению

    def learn(self, state, action, reward, next_state):
        """Обновление Q-значения на основе полученного опыта."""
        discretized_state = self.discretize_state(state)
        discretized_next_state = self.discretize_state(next_state)

        # Находим лучшее Q-значение для следующего состояния
        if discretized_next_state not in self.q_table:
            # Если это новое состояние, инициализируем Q-значение нулями
            self.q_table[discretized_next_state] = np.zeros(self.env.action_space.shape)

        # Вычисляем целевое Q-значение
        target_q = reward + self.discount_factor * np.max(self.q_table[discretized_next_state])

        # Обновляем Q-значение для текущего состояния и действия
        if discretized_state not in self.q_table:
          self.q_table[discretized_state] = action

        old_value = self.q_table[discretized_state]
        self.q_table[discretized_state] = (1 - self.learning_rate) * old_value + self.learning_rate * action

        # Обновляем Q-значение для текущего состояния и действия
        self.q_table[discretized_state] = action

env = BuildingEnv()
agent = QLearningAgent(env)

# Обучение
episodes = 10
all_rewards = []

for episode in range(episodes):
    state, _ = env.reset() #reset возвращает кортеж (state, info), поэтому необходимо его распаковать.
    done = False
    truncated = False
    total_reward = 0

    while not done and not truncated:
        action = agent.choose_action(state)
        next_state, reward, done, truncated, _ = env.step(action)
        agent.learn(state, action, reward, next_state)
        state = next_state
        total_reward += reward

    all_rewards.append(total_reward)
    env.render_episode(episode+1) # Визуализация эпизода

    if (episode + 1) % 100 == 0:
        print(f"Эпизод {episode + 1}, Суммарная награда: {total_reward}")

# 5. График суммарных наград по эпизодам
plt.figure(figsize=(10, 5))
plt.plot(range(1, episodes + 1), all_rewards, marker='o')
plt.title('Суммарная награда по эпизодам')
plt.xlabel('Эпизод')
plt.ylabel('Суммарная награда')
plt.grid(True)
plt.show()

#Загрузка и анализ данных:
data_soil = pd.read_csv('soil_data.csv') # замените 'soil_data.csv' на имя вашего файла
print(data_soil.head())
print(data_soil.describe())
print(data_soil.isnull().sum())

# Заполнение пропусков (если есть, простым способом)
imputer = SimpleImputer(strategy='mean')  # или 'median', 'most_frequent'
data_soil.iloc[:, :-1] = imputer.fit_transform(data_soil.iloc[:, :-1])

# Разделение признаков и целевой переменной
X = data_soil.drop('SoilType', axis=1)
y = data_soil['SoilType']

# Разбиение на тренировочный и тестовый наборы
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Создание и обучение модели
model_soil = RandomForestClassifier(random_state=42)
model_soil.fit(X_train, y_train)

evaluate_classification_model(model_soil, X_test, y_test)

def remove_outliers_iqr(df, column, factor=1.5):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - factor * IQR
    upper_bound = Q3 + factor * IQR
    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]

# Убираем выбросы из числовых столбцов (пример)
numerical_columns = X.select_dtypes(include=np.number).columns
for column in numerical_columns:
    X_train = remove_outliers_iqr(X_train, column)
    y_train = y_train[X_train.index] # Синхронизируем индексы

model_soil_no_outliers = RandomForestClassifier(random_state=42)
model_soil_no_outliers.fit(X_train, y_train)
evaluate_classification_model(model_soil_no_outliers, X_test, y_test)

"""Задание 5: Прогнозирование теплопотерь здания на основе данных об его конструкции и климате

Описание: Точное прогнозирование теплопотерь здания необходимо для оптимизации систем отопления и вентиляции, снижения энергопотребления и повышения комфорта. В этом задании вам предстоит разработать модель машинного обучения, предсказывающую общие теплопотери здания на основе данных о его конструкции и климатических условиях.
Данные: Предоставляется датасет со следующими признаками:
Area (м2) - площадь здания
Height (м) - высота здания
WallUValue (Вт/м2*К) - коэффициент теплопередачи стен
RoofUValue (Вт/м2*К) - коэффициент теплопередачи крыши
WindowUValue (Вт/м2*К) - коэффициент теплопередачи окон
WindowAreaRatio (%) - процент площади окон от общей площади стен
HeatingDegreeDays (градусо-дни) - количество градусо-дней отопительного периода
Orientation (категориальный) - ориентация здания (север, юг, восток, запад)
HeatLoss (кВт) - общие теплопотери здания (целевая переменная)
Этапы работы: (Повторяют структуру исходного задания)
1.  Получите данные и загрузите их в рабочую среду (Jupyter Notebook или другую).
2.  Проведите первичный анализ.  Изучите распределение целевой переменной (`HeatLoss`) и основных признаков.  Оцените наличие пропущенных значений и выбросов.
3.  Разделите выборку на обучающее и тестовое подмножество. 80% данных оставить на обучающее множество, 20% на тестовое. Обучите модель дерева решений RandomForestClassifier на обучающем множестве.
4.  Для тестового множества предскажите теплопотери здания и сравните с истинным значением, посчитав точность предсказания модели (accuracy).
5.  Обработайте выбросы в данных:
    а) Визуализируйте распределение значений для каждой переменной. Можно использовать функции `sns.boxplot`, `sns.distplot`. Есть ли признаки с нормальным распределением?
    b) Исследуйте признаки на выбросы несколькими способами.
    c) Удалите выбросы. \*Посчитайте процент удаленных записей от общего числа записей.
6.  Повторите п. 4, п. 5.
7.  Сформулируйте выводы по проделанной работе:
    а) Кратко опишите, какие преобразования были сделаны с данными.
    b) Сравните точность двух моделей.
    c) Напишите свое мнение, нужно ли исследовать данные на выбросы, для чего это делается, плюсы и минусы подхода.

Инструменты:
Jupyter Notebook/Google Colab
GitHub
данные для обучения моделей (предоставляются)
модель дерева решений RandomForestClassifier
"""

#Загрузка и анализ данных:
data_heatloss = pd.read_csv('heatloss_data.csv') # замените 'heatloss_data.csv' на имя вашего файла
print(data_heatloss.head())
print(data_heatloss.describe())
print(data_heatloss.isnull().sum())

# Заполнение пропусков (если есть, простым способом)
imputer = SimpleImputer(strategy='mean')
data_heatloss.iloc[:, :-1] = imputer.fit_transform(data_heatloss.iloc[:, :-1])

# Разделение признаков и целевой переменной
X = data_heatloss.drop('HeatLoss', axis=1)
y = data_heatloss['HeatLoss']

# Кодирование категориальной переменной "Orientation"
encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
X_encoded = encoder.fit_transform(data_heatloss[['Orientation']])
X_encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(['Orientation']))
X = pd.concat([X, X_encoded_df], axis=1)
X.drop('Orientation', axis=1, inplace=True)

# Разделение на тренировочный и тестовый наборы
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Масштабирование признаков
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Создание и обучение модели
model_heatloss = RandomForestRegressor(random_state=42)
model_heatloss.fit(X_train, y_train)

evaluate_regression_model(model_heatloss, X_test, y_test)

from scipy import stats

def remove_outliers_zscore(df, column, threshold=3):
    z_scores = np.abs(stats.zscore(df[column]))
    return df[z_scores < threshold]

# Убираем выбросы из числовых столбцов (пример)
numerical_columns = X.columns
for column in numerical_columns:
    X_train = remove_outliers_zscore(X_train, column)
    y_train = y_train[X_train.index] # Синхронизируем индексы

model_heatloss_no_outliers = RandomForestRegressor(random_state=42)
model_heatloss_no_outliers.fit(X_train, y_train)
evaluate_regression_model(model_heatloss_no_outliers, X_test, y_test)

"""Задание 6: Прогнозирование сроков строительства на основе исторических данных

Описание: Точное прогнозирование сроков строительства помогает избежать задержек, перерасхода бюджета и других проблем. В этом задании вам предстоит разработать модель машинного обучения, предсказывающую сроки строительства на основе исторических данных о завершенных проектах.

Данные: Предоставляется датасет с информацией о завершенных строительных проектах:

ProjectType (категориальный) - тип проекта (жилой дом, коммерческое здание, промышленный объект, инфраструктурный проект)
Area (м2) - площадь здания
Complexity (число) - оценочный показатель сложности проекта (от 1 до 10)
NumWorkers (человек) - среднее количество рабочих на стройплощадке
MaterialsCost (руб.) - стоимость материалов
EquipmentCost (руб.) - стоимость оборудования
PermitDelay (дни) - задержка в получении разрешительной документации
WeatherConditions (категориальный) - преобладающие погодные условия (солнечно, дождливо, снежно)
ConstructionTime (дни) - срок строительства (целевая переменная)
Этапы работы: (Повторяют структуру исходного задания)

Получите данные и загрузите их в рабочую среду (Jupyter Notebook или другую).
Проведите первичный анализ. Изучите распределение целевой переменной (ConstructionTime) и основных признаков. Оцените наличие пропущенных значений и выбросов.
Разделите выборку на обучающее и тестовое подмножество. 80% данных оставить на обучающее множество, 20% на тестовое. Обучите модель дерева решений RandomForestClassifier на обучающем множестве.
Для тестового множества предскажите сроки строительства и сравните с истинным значением, посчитав точность предсказания модели (accuracy).
Обработайте выбросы в данных: а) Визуализируйте распределение значений для каждой переменной. Можно использовать функции sns.boxplot, sns.distplot. Есть ли признаки с нормальным распределением? b) Исследуйте признаки на выбросы несколькими способами. c) Удалите выбросы. *Посчитайте процент удаленных записей от общего числа записей.
Повторите п. 4, п. 5.
Сформулируйте выводы по проделанной работе: а) Кратко опишите, какие преобразования были сделаны с данными. b) Сравните точность двух моделей. c) Напишите свое мнение, нужно ли исследовать данные на выбросы, для чего это делается, плюсы и минусы подхода.
Инструменты:

Jupyter Notebook/Google Colab
GitHub
данные для обучения моделей (предоставляются)
модель дерева решений RandomForestClassifier
Рекомендации по решению:

Внимательно изучите данные: Проведите EDA (Exploratory Data Analysis) для понимания структуры данных, распределения признаков и взаимосвязей между ними.
Обработайте категориальные признаки: Используйте One-Hot Encoding или Label Encoding для преобразования категориальных признаков в числовые.
Масштабируйте данные: Используйте StandardScaler или MinMaxScaler для масштабирования числовых признаков, чтобы улучшить производительность модели.
Поэкспериментируйте с разными моделями: Попробуйте различные алгоритмы машинного обучения, такие как линейная регрессия, SVM, градиентный бустинг, нейронные сети.
Настройте гиперпараметры: Используйте GridSearchCV или RandomizedSearchCV для поиска оптимальных гиперпараметров модели.
Оцените качество модели: Используйте подходящие метрики для оценки качества модели (например, accuracy, precision, recall, F1-score для задач классификации, RMSE, MAE, R2 для задач регрессии).
Интерпретируйте результаты: Попробуйте понять, какие факторы оказывают наибольшее влияние на целевую переменную.
Оформите решение: Четко и структурированно представьте результаты своей работы в Jupyter Notebook или Google Colab.
"""

data_construction = pd.read_csv('construction_data.csv') # замените 'construction_data.csv' на имя вашего файла
print(data_construction.head())
print(data_construction.describe())
print(data_construction.isnull().sum())

# Заполнение пропусков (если есть, простым способом)
imputer = SimpleImputer(strategy='mean')
data_construction.iloc[:, :-1] = imputer.fit_transform(data_construction.iloc[:, :-1])

# Разделение признаков и целевой переменной
X = data_construction.drop('ConstructionTime', axis=1)
y = data_construction['ConstructionTime']

# Кодирование категориальных переменных "ProjectType" и "WeatherConditions"
encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
X_encoded = encoder.fit_transform(X[['ProjectType', 'WeatherConditions']])
X_encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(['ProjectType', 'WeatherConditions']))
X = pd.concat([X, X_encoded_df], axis=1)
X.drop(['ProjectType', 'WeatherConditions'], axis=1, inplace=True)

# Разделение на тренировочный и тестовый наборы
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Масштабирование признаков
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Создание и обучение модели
model_construction = RandomForestRegressor(random_state=42)
model_construction.fit(X_train, y_train)

evaluate_regression_model(model_construction, X_test, y_test)

from sklearn.ensemble import IsolationForest

# Инициализация и обучение модели Isolation Forest
iso_forest = IsolationForest(n_estimators=100, contamination='auto', random_state=42)
iso_forest.fit(X_train)

# Получение предсказаний о том, является ли точка выбросом
outlier_predictions = iso_forest.predict(X_train)

# Выбор только тех строк, которые не являются выбросами
X_train = X_train[outlier_predictions != -1]
y_train = y_train[outlier_predictions != -1]

model_construction_no_outliers = RandomForestRegressor(random_state=42)
model_construction_no_outliers.fit(X_train, y_train)
evaluate_regression_model(model_construction_no_outliers, X_test, y_test)

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.metrics import accuracy_score, mean_squared_error, r2_score
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer  # Для обработки пропущенных значений
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import LabelEncoder

# Вспомогательная функция для оценки модели классификации
def evaluate_classification_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"Accuracy: {accuracy:.4f}")

# Вспомогательная функция для оценки модели регрессии
def evaluate_regression_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)
    print(f"RMSE: {rmse:.4f}")
    print(f"R2 Score: {r2:.4f}")


################################################################################
# Задание 4: Классификация типов грунтов
################################################################################

soil_data = {
    'Depth': [1.5, 3.0, 4.5, 6.0, 7.5, 9.0, 10.5, 12.0, 13.5, 15.0, 1.0, 2.5, 4.0, 5.5, 7.0, 8.5, 10.0, 11.5, 13.0, 14.5, 1.2, 2.7, 4.2, 5.7, 7.2],
    'SPT_N': [12, 25, 8, 35, 18, 10, 28, 7, 40, 20, 11, 23, 9, 32, 17, 12, 26, 6, 38, 19, 13, 24, 10, 33, 16],
    'WaterContent': [15.2, 8.9, 22.5, 5.1, 18.7, 25.4, 7.2, 24.1, 4.5, 17.3, 16.8, 9.5, 21.2, 5.8, 19.1, 26.1, 6.9, 23.5, 4.8, 16.7, 14.9, 9.1, 20.9, 6.1, 18.9],
    'PlasticityIndex': [8.5, 3.2, 12.1, 1.8, 9.9, 13.5, 2.5, 11.4, 1.5, 8.7, 9.2, 3.5, 12.5, 2.1, 9.1, 14.2, 2.8, 10.8, 1.2, 8.4, 8.1, 3.8, 11.8, 2.4, 8.9],
    'LiquidLimit': [22.1, 15.7, 28.5, 10.2, 24.6, 30.9, 14.3, 27.1, 9.5, 23.2, 23.8, 16.5, 29.2, 11.1, 23.9, 31.7, 13.9, 26.5, 9.1, 22.5, 21.8, 15.9, 28.8, 11.5, 23.5],
    'ClayContent': [25.3, 5.1, 52.7, 1.2, 35.9, 58.4, 4.3, 50.1, 0.9, 34.2, 27.5, 5.5, 53.5, 1.5, 33.8, 59.2, 4.7, 48.9, 0.7, 32.5, 24.9, 5.9, 51.9, 1.8, 33.2],
    'SiltContent': [45.7, 15.8, 32.1, 3.5, 39.5, 28.9, 14.7, 34.3, 3.1, 41.7, 43.2, 16.2, 31.5, 3.9, 40.1, 27.9, 15.1, 35.0, 3.3, 42.3, 46.1, 15.5, 32.4, 3.6, 40.4],
    'SandContent': [28.1, 78.3, 14.3, 10.1, 23.7, 11.7, 79.9, 14.5, 9.7, 23.1, 28.2, 77.6, 14.1, 10.5, 24.9, 11.8, 79.3, 14.7, 9.3, 24.1, 28.8, 77.9, 14.7, 10.8, 25.5],
    'GravelContent': [0.9, 0.8, 0.9, 85.2, 0.9, 1.0, 1.1, 1.1, 86.8, 1.3, 1.1, 1.2, 1.7, 84.0, 1.0, 0.8, 1.3, 1.1, 87.0, 1.5, 1.3, 0.9, 1.4, 83.5, 1.2],
    'SoilType': ['Clay', 'Sand', 'Silt', 'Gravel', 'Loam', 'Clay', 'Sand', 'Silt', 'Gravel', 'Loam', 'Clay', 'Sand', 'Silt', 'Gravel', 'Loam', 'Clay', 'Sand', 'Silt', 'Gravel', 'Loam', 'Clay', 'Sand', 'Silt', 'Gravel', 'Loam']
}

df_soil = pd.DataFrame(soil_data)
print("Dataframe: ", df_soil.head())

# 1.  Подготовка данных и разделение на выборки:

X = df_soil.drop('SoilType', axis=1)
y = df_soil['SoilType']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# 2. Создание и обучение модели
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

evaluate_classification_model(model, X_test, y_test)

################################################################################
# Задание 5: Прогнозирование теплопотерь здания
################################################################################

heatloss_data = {
    'Area': [150, 200, 120, 180, 220, 140, 190, 110, 170, 210, 130, 160, 230, 155, 195, 115, 175, 215, 135, 165, 235],
    'Height': [3.5, 4.0, 3.0, 3.8, 4.2, 3.3, 3.9, 2.8, 3.7, 4.1, 3.2, 3.6, 4.3, 3.4, 3.85, 2.9, 3.75, 4.15, 3.1, 3.5, 4.4],
    'WallUValue': [1.2, 1.0, 1.3, 1.1, 0.9, 1.25, 1.05, 1.4, 1.15, 0.95, 1.35, 1.2, 0.85, 1.22, 1.08, 1.38, 1.12, 0.92, 1.32, 1.18, 0.82],
    'RoofUValue': [0.8, 0.7, 0.9, 0.75, 0.6, 0.85, 0.72, 0.95, 0.78, 0.65, 0.82, 0.8, 0.55, 0.88, 0.74, 0.93, 0.76, 0.62, 0.8, 0.78, 0.52],
    'WindowUValue': [2.5, 2.2, 2.7, 2.3, 2.0, 2.6, 2.25, 2.8, 2.35, 2.1, 2.65, 2.5, 1.9, 2.55, 2.28, 2.75, 2.32, 2.05, 2.62, 2.48, 1.85],
    'WindowAreaRatio': [15, 20, 12, 18, 22, 14, 19, 10, 17, 21, 13, 16, 23, 15.5, 19.5, 11, 17.5, 21.5, 13.5, 16.5, 23.5],
    'HeatingDegreeDays': [3000, 2500, 3500, 2800, 2200, 3200, 2600, 3700, 2900, 2300, 3300, 3100, 2100, 3050, 2650, 3600, 2850, 2250, 3250, 3075, 2050],
    'Orientation': ['North', 'South', 'East', 'West', 'North', 'South', 'East', 'West', 'North', 'South', 'East', 'West', 'North', 'South', 'East', 'West', 'North', 'South', 'East', 'West', 'North'],
    'HeatLoss': [15.5, 18.2, 13.8, 17.1, 19.5, 14.9, 17.8, 13.2, 16.5, 19.0, 14.4, 15.9, 20.1, 15.2, 17.5, 13.5, 16.8, 19.2, 14.1, 16.2, 20.4]
}

df_heatloss = pd.DataFrame(heatloss_data)

# 1.  Подготовка данных и разделение на выборки:
X = df_heatloss.drop('HeatLoss', axis=1)
y = df_heatloss['HeatLoss']
# Кодирование категориальной переменной "Orientation"
encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
X_encoded = encoder.fit_transform(df_heatloss[['Orientation']])
X_encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(['Orientation']))
X = pd.concat([X, X_encoded_df], axis=1)
X.drop('Orientation', axis=1, inplace=True)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Масштабирование признаков
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# 2. Создание и обучение модели
model = RandomForestRegressor(random_state=42)
model.fit(X_train, y_train)
# 3. Оценка
evaluate_regression_model(model, X_test, y_test)

################################################################################
# Задание 6: Прогнозирование сроков строительства
################################################################################

construction_data = {
    'ProjectType': ['Residential', 'Commercial', 'Industrial', 'Infrastructure', 'Residential', 'Commercial', 'Industrial', 'Infrastructure', 'Residential', 'Commercial', 'Industrial', 'Infrastructure', 'Residential', 'Commercial', 'Industrial', 'Infrastructure', 'Residential', 'Commercial', 'Industrial', 'Infrastructure', 'Residential', 'Commercial', 'Industrial', 'Infrastructure'],
    'Area': [1500, 2500, 5000, 10000, 1200, 2000, 4500, 9000, 1800, 2800, 5500, 11000, 1400, 2300, 4800, 9500, 1600, 2600, 5200, 10500, 1300, 2100, 4600, 9200],
    'Complexity': [5, 7, 9, 8, 4, 6, 8, 7, 6, 8, 10, 9, 4, 6, 8, 7, 5, 7, 9, 8, 3, 5, 7, 6],
    'NumWorkers': [15, 25, 50, 100, 12, 20, 45, 90, 18, 28, 55, 110, 14, 23, 48, 95, 16, 26, 52, 105, 13, 21, 46, 92],
    'MaterialsCost': [500000, 1200000, 3000000, 5000000, 400000, 1000000, 2800000, 4500000, 600000, 1300000, 3200000, 5500000, 450000, 1100000, 2900000, 4700000, 550000, 1250000, 3100000, 5200000, 350000, 900000, 2700000, 4400000],
    'EquipmentCost': [100000, 300000, 800000, 1500000, 80000, 250000, 750000, 1400000, 120000, 320000, 850000, 1600000, 90000, 270000, 780000, 1450000, 110000, 310000, 820000, 1550000, 70000, 220000, 720000, 1350000],
    'PermitDelay': [0, 10, 20, 30, 0, 5, 15, 25, 0, 8, 18, 28, 0, 7, 17, 27, 0, 9, 19, 29, 0, 6, 16, 26],
    'WeatherConditions': ['Sunny', 'Rainy', 'Snowy', 'Mixed', 'Sunny', 'Rainy', 'Snowy', 'Mixed', 'Sunny', 'Rainy', 'Snowy', 'Mixed', 'Sunny', 'Rainy', 'Snowy', 'Mixed', 'Sunny', 'Rainy', 'Snowy', 'Mixed', 'Sunny', 'Rainy', 'Snowy', 'Mixed'],
    'ConstructionTime': [365, 540, 730, 900, 330, 480, 700, 850, 390, 560, 750, 920, 350, 520, 720, 880, 370, 550, 740, 910, 340, 500, 710, 860]
}
df_construction = pd.DataFrame(construction_data)

# 1.  Подготовка данных и разделение на выборки:
X = df_construction.drop('ConstructionTime', axis=1)
y = df_construction['ConstructionTime']

# Кодирование категориальных переменных "ProjectType" и "WeatherConditions"
encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
X_encoded = encoder.fit_transform(X[['ProjectType', 'WeatherConditions']])
X_encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(['ProjectType', 'WeatherConditions']))
X = pd.concat([X, X_encoded_df], axis=1)
X.drop(['ProjectType', 'WeatherConditions'], axis=1, inplace=True)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Масштабирование признаков
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# 2. Создание и обучение модели
model = RandomForestRegressor(random_state=42)
model.fit(X_train, y_train)
# 3. Оценка
evaluate_regression_model(model, X_test, y_test)

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.metrics import accuracy_score, mean_squared_error, r2_score
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer  # Для обработки пропущенных значений
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import LabelEncoder

# Вспомогательная функция для оценки модели классификации
def evaluate_classification_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"Точность: {accuracy:.4f}")

# Вспомогательная функция для оценки модели регрессии
def evaluate_regression_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)
    print(f"RMSE: {rmse:.4f}")
    print(f"R2: {r2:.4f}")


################################################################################
# Задание 4: Классификация типов грунтов
################################################################################

soil_data = {
    'Depth': [1.5, 3.0, 4.5, 6.0, 7.5, 9.0, 10.5, 12.0, 13.5, 15.0, 1.0, 2.5, 4.0, 5.5, 7.0, 8.5, 10.0, 11.5, 13.0, 14.5, 1.2, 2.7, 4.2, 5.7, 7.2],
    'SPT_N': [12, 25, 8, 35, 18, 10, 28, 7, 40, 20, 11, 23, 9, 32, 17, 12, 26, 6, 38, 19, 13, 24, 10, 33, 16],
    'WaterContent': [15.2, 8.9, 22.5, 5.1, 18.7, 25.4, 7.2, 24.1, 4.5, 17.3, 16.8, 9.5, 21.2, 5.8, 19.1, 26.1, 6.9, 23.5, 4.8, 16.7, 14.9, 9.1, 20.9, 6.1, 18.9],
    'PlasticityIndex': [8.5, 3.2, 12.1, 1.8, 9.9, 13.5, 2.5, 11.4, 1.5, 8.7, 9.2, 3.5, 12.5, 2.1, 9.1, 14.2, 2.8, 10.8, 1.2, 8.4, 8.1, 3.8, 11.8, 2.4, 8.9],
    'LiquidLimit': [22.1, 15.7, 28.5, 10.2, 24.6, 30.9, 14.3, 27.1, 9.5, 23.2, 23.8, 16.5, 29.2, 11.1, 23.9, 31.7, 13.9, 26.5, 9.1, 22.5, 21.8, 15.9, 28.8, 11.5, 23.5],
    'ClayContent': [25.3, 5.1, 52.7, 1.2, 35.9, 58.4, 4.3, 50.1, 0.9, 34.2, 27.5, 5.5, 53.5, 1.5, 33.8, 59.2, 4.7, 48.9, 0.7, 32.5, 24.9, 5.9, 51.9, 1.8, 33.2],
    'SiltContent': [45.7, 15.8, 32.1, 3.5, 39.5, 28.9, 14.7, 34.3, 3.1, 41.7, 43.2, 16.2, 31.5, 3.9, 40.1, 27.9, 15.1, 35.0, 3.3, 42.3, 46.1, 15.5, 32.4, 3.6, 40.4],
    'SandContent': [28.1, 78.3, 14.3, 10.1, 23.7, 11.7, 79.9, 14.5, 9.7, 23.1, 28.2, 77.6, 14.1, 10.5, 24.9, 11.8, 79.3, 14.7, 9.3, 24.1, 28.8, 77.9, 14.7, 10.8, 25.5],
    'GravelContent': [0.9, 0.8, 0.9, 85.2, 0.9, 1.0, 1.1, 1.1, 86.8, 1.3, 1.1, 1.2, 1.7, 84.0, 1.0, 0.8, 1.3, 1.1, 87.0, 1.5, 1.3, 0.9, 1.4, 83.5, 1.2],
    'SoilType': ['Clay', 'Sand', 'Silt', 'Gravel', 'Loam', 'Clay', 'Sand', 'Silt', 'Gravel', 'Loam', 'Clay', 'Sand', 'Silt', 'Gravel', 'Loam', 'Clay', 'Sand', 'Silt', 'Gravel', 'Loam', 'Clay', 'Sand', 'Silt', 'Gravel', 'Loam']
}

df_soil = pd.DataFrame(soil_data)

# 1.  Графики для анализа
# Диаграмма рассеяния для глубины vs. SPT_N
plt.figure(figsize=(8, 6))
sns.scatterplot(x='Depth', y='SPT_N', hue='SoilType', data=df_soil)
plt.title('Глубина vs. SPT_N')
plt.xlabel('Глубина (м)')
plt.ylabel('SPT_N')
plt.show()

# Ящик с усами для влажности по типам почвы
plt.figure(figsize=(8, 6))
sns.boxplot(x='SoilType', y='WaterContent', data=df_soil)
plt.title('Влажность по типам почвы')
plt.xlabel('Тип почвы')
plt.ylabel('Влажность (%)')
plt.show()

# Гистограмма для индекса пластичности
plt.figure(figsize=(8, 6))
sns.histplot(df_soil['PlasticityIndex'], kde=True)
plt.title('Распределение индекса пластичности')
plt.xlabel('Индекс пластичности (%)')
plt.ylabel('Частота')
plt.show()

# Матрица корреляции для числовых признаков
numeric_soil_data = df_soil.select_dtypes(include=np.number)
correlation_matrix = numeric_soil_data.corr()
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Матрица корреляции для данных о почве')
plt.show()

################################################################################
# Задание 5: Прогнозирование теплопотерь здания
################################################################################

heatloss_data = {
    'Area': [150, 200, 120, 180, 220, 140, 190, 110, 170, 210, 130, 160, 230, 155, 195, 115, 175, 215, 135, 165, 235],
    'Height': [3.5, 4.0, 3.0, 3.8, 4.2, 3.3, 3.9, 2.8, 3.7, 4.1, 3.2, 3.6, 4.3, 3.4, 3.85, 2.9, 3.75, 4.15, 3.1, 3.5, 4.4],
    'WallUValue': [1.2, 1.0, 1.3, 1.1, 0.9, 1.25, 1.05, 1.4, 1.15, 0.95, 1.35, 1.2, 0.85, 1.22, 1.08, 1.38, 1.12, 0.92, 1.32, 1.18, 0.82],
    'RoofUValue': [0.8, 0.7, 0.9, 0.75, 0.6, 0.85, 0.72, 0.95, 0.78, 0.65, 0.82, 0.8, 0.55, 0.88, 0.74, 0.93, 0.76, 0.62, 0.8, 0.78, 0.52],
    'WindowUValue': [2.5, 2.2, 2.7, 2.3, 2.0, 2.6, 2.25, 2.8, 2.35, 2.1, 2.65, 2.5, 1.9, 2.55, 2.28, 2.75, 2.32, 2.05, 2.62, 2.48, 1.85],
    'WindowAreaRatio': [15, 20, 12, 18, 22, 14, 19, 10, 17, 21, 13, 16, 23, 15.5, 19.5, 11, 17.5, 21.5, 13.5, 16.5, 23.5],
    'HeatingDegreeDays': [3000, 2500, 3500, 2800, 2200, 3200, 2600, 3700, 2900, 2300, 3300, 3100, 2100, 3050, 2650, 3600, 2850, 2250, 3250, 3075, 2050],
    'Orientation': ['North', 'South', 'East', 'West', 'North', 'South', 'East', 'West', 'North', 'South', 'East', 'West', 'North', 'South', 'East', 'West', 'North', 'South', 'East', 'West', 'North'],
    'HeatLoss': [15.5, 18.2, 13.8, 17.1, 19.5, 14.9, 17.8, 13.2, 16.5, 19.0, 14.4, 15.9, 20.1, 15.2, 17.5, 13.5, 16.8, 19.2, 14.1, 16.2, 20.4]
}

df_heatloss = pd.DataFrame(heatloss_data)

# 1. Графики для анализа
# Зависимость теплопотерь от площади
plt.figure(figsize=(8, 6))
sns.scatterplot(x='Area', y='HeatLoss', hue='Orientation', data=df_heatloss)
plt.title('Теплопотери vs. Площадь')
plt.xlabel('Площадь (м^2)')
plt.ylabel('Теплопотери (кВт)')
plt.show()

# Boxplot для коэффициентов теплопередачи
plt.figure(figsize=(10, 6))
sns.boxplot(data=df_heatloss[['WallUValue', 'RoofUValue', 'WindowUValue']])
plt.title('Ящик с усами для коэффициентов теплопередачи')
plt.ylabel('Коэффициент теплопередачи (Вт/м^2*K)')
plt.show()

# Зависимость теплопотерь от градусо-дней отопительного периода
plt.figure(figsize=(8, 6))
sns.scatterplot(x='HeatingDegreeDays', y='HeatLoss', data=df_heatloss)
plt.title('Теплопотери vs. Градусо-дни отопительного периода')
plt.xlabel('Градусо-дни отопительного периода')
plt.ylabel('Теплопотери (кВт)')
plt.show()

# Pairplot для анализа взаимосвязей между признаками
pair_cols = ['Area', 'Height', 'WallUValue', 'HeatLoss']
sns.pairplot(df_heatloss[pair_cols])
plt.suptitle('Матрица диаграмм рассеяния для данных о теплопотерях', y=1.02)
plt.show()

################################################################################
# Задание 6: Прогнозирование сроков строительства
################################################################################

construction_data = {
    'ProjectType': ['Residential', 'Commercial', 'Industrial', 'Infrastructure', 'Residential', 'Commercial', 'Industrial', 'Infrastructure', 'Residential', 'Commercial', 'Industrial', 'Infrastructure', 'Residential', 'Commercial', 'Industrial', 'Infrastructure', 'Residential', 'Commercial', 'Industrial', 'Infrastructure', 'Residential', 'Commercial', 'Industrial', 'Infrastructure'],
    'Area': [1500, 2500, 5000, 10000, 1200, 2000, 4500, 9000, 1800, 2800, 5500, 11000, 1400, 2300, 4800, 9500, 1600, 2600, 5200, 10500, 1300, 2100, 4600, 9200],
    'Complexity': [5, 7, 9, 8, 4, 6, 8, 7, 6, 8, 10, 9, 4, 6, 8, 7, 5, 7, 9, 8, 3, 5, 7, 6],
    'NumWorkers': [15, 25, 50, 100, 12, 20, 45, 90, 18, 28, 55, 110, 14, 23, 48, 95, 16, 26, 52, 105, 13, 21, 46, 92],
    'MaterialsCost': [500000, 1200000, 3000000, 5000000, 400000, 1000000, 2800000, 4500000, 600000, 1300000, 3200000, 5500000, 450000, 1100000, 2900000, 4700000, 550000, 1250000, 3100000, 5200000, 350000, 900000, 2700000, 4400000],
    'EquipmentCost': [100000, 300000, 800000, 1500000, 80000, 250000, 750000, 1400000, 120000, 320000, 850000, 1600000, 90000, 270000, 780000, 1450000, 110000, 310000, 820000, 1550000, 70000, 220000, 720000, 1350000],
    'PermitDelay': [0, 10, 20, 30, 0, 5, 15, 25, 0, 8, 18, 28, 0, 7, 17, 27, 0, 9, 19, 29, 0, 6, 16, 26],
    'WeatherConditions': ['Sunny', 'Rainy', 'Snowy', 'Mixed', 'Sunny', 'Rainy', 'Snowy', 'Mixed', 'Sunny', 'Rainy', 'Snowy', 'Mixed', 'Sunny', 'Rainy', 'Snowy', 'Mixed', 'Sunny', 'Rainy', 'Snowy', 'Mixed', 'Sunny', 'Rainy', 'Snowy', 'Mixed'],
    'ConstructionTime': [365, 540, 730, 900, 330, 480, 700, 850, 390, 560, 750, 920, 350, 520, 720, 880, 370, 550, 740, 910, 340, 500, 710, 860]
}
df_construction = pd.DataFrame(construction_data)

# 1. Графики для анализа
# Диаграмма рассеяния для площади vs. Сроки строительства
plt.figure(figsize=(8, 6))
sns.scatterplot(x='Area', y='ConstructionTime', hue='ProjectType', data=df_construction)
plt.title('Сроки строительства vs. Площадь')
plt.xlabel('Площадь (м^2)')
plt.ylabel('Сроки строительства (дни)')
plt.show()

# Boxplot для Стоимости материалов по типу проекта
plt.figure(figsize=(10, 6))
sns.boxplot(x='ProjectType', y='MaterialsCost', data=df_construction)
plt.title('Стоимость материалов по типу проекта')
plt.xlabel('Тип проекта')
plt.ylabel('Стоимость материалов (руб)')
plt.xticks(rotation=45)  # Поворот подписей для читаемости
plt.show()

# Гистограмма для Сроков строительства
plt.figure(figsize=(8, 6))
sns.histplot(df_construction['ConstructionTime'], kde=True)
plt.title('Распределение сроков строительства')
plt.xlabel('Сроки строительства (дни)')
plt.ylabel('Частота')
plt.show()

# Swarmplot для Погодных условий vs. Сроков строительства
plt.figure(figsize=(10, 6))
sns.swarmplot(x='WeatherConditions', y='ConstructionTime', data=df_construction)
plt.title('Сроки строительства vs. Погодные условия')
plt.xlabel('Погодные условия')
plt.ylabel('Сроки строительства (дни)')
plt.xticks(rotation=45)
plt.show()